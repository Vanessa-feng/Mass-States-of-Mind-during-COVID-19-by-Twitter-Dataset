{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if data dir in hpcc\n",
    "os.chdir(\"/bigdata/statsdept/xfeng044/stat209/xfeng044/data\")\n",
    "\n",
    "#  Use glob to match the pattern ‘csv’\n",
    "dir1 = 'Summary_Details/202*/202*.'\n",
    "dir2 = 'Summary_Hashtag/202*/202*.'\n",
    "dir3 = 'Summary_Sentiment/202*/202*.'\n",
    "file_type = 'csv'\n",
    "all_summ = [i for i in glob.glob(dir1 + file_type)]\n",
    "all_hash = [i for i in glob.glob(dir2 + file_type)]\n",
    "all_sent = [i for i in glob.glob(dir3 + file_type)]\n",
    "# print(all_summ[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "####-----------------------FOR Hashtag--------------#######\n",
    "# Combine all files from a given start_time and end_time\n",
    "\n",
    "## define start date\n",
    "startTime = '2021-01-01 00:00:00'\n",
    "endTime = '2021-02-28 23:00:00'\n",
    "\n",
    "## define the file scope\n",
    "files = all_hash\n",
    "# files = ['2020_05_31_23_Summary_Hashtag.csv',\n",
    "#  '2019_05_31_23_Summary_Hashtag.csv',\n",
    "#  '2020_01_31_23_Summary_Hashtag.csv',\n",
    "#  '2020_03_30_22_Summary_Hashtag.csv']\n",
    "\n",
    "\n",
    "## define start and end time\n",
    "startTime = pd.to_datetime(startTime)\n",
    "endTime = pd.to_datetime(endTime)\n",
    "\n",
    "\n",
    "## conbine file in certain interval\n",
    "out = []\n",
    "for x in files:\n",
    "    temp = '_'.join(x.split('/')[2].split('_',4)[:-1])                    \n",
    "    date = pd.to_datetime(temp,  format='%Y_%m_%d_%H')\n",
    "\n",
    "    if date >= startTime and date <= endTime:\n",
    "        temp = pd.read_csv(x,encoding= 'unicode_escape')\n",
    "        #print(date)\n",
    "        temp['Year'] = date.year\n",
    "        temp['Month'] = date.month\n",
    "        temp['Day'] = date.day\n",
    "        out.append(temp)\n",
    "        \n",
    "combined_csv = pd.concat(out, ignore_index=True)\n",
    "# # test output\n",
    "# combined_csv.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------get top x hashtags per day-------##\n",
    "combined_csv = combined_csv.groupby(['Year','Month','Day','Hastag']).count() ##### 1-9 use hashtag, 10-12 use hastag in original table\n",
    "combined_csv = combined_csv.sort_values(['Year','Month','Day','Tweet_ID'],ascending=False).groupby(['Month','Day']).head(100).reset_index()\n",
    "\n",
    "combined_csv.to_csv('combined_hash_from_{}_to_{}.csv'.format(startTime.date(),endTime.date()), \n",
    "                     index=False,encoding=\"utf-8\",errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1223335138370760705</td>\n",
       "      <td>#China</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1223335138370760705</td>\n",
       "      <td>#coronavirus</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1223335138370760705</td>\n",
       "      <td>#CoronavirusOutbreak</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1223335138756648965</td>\n",
       "      <td>#coronaravirus</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1223335138895056899</td>\n",
       "      <td>#coronavirus</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153518</th>\n",
       "      <td>1220602122007281671</td>\n",
       "      <td>#coronavirus</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153519</th>\n",
       "      <td>1220602122007281671</td>\n",
       "      <td>#CoronavirusOutbreak</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153520</th>\n",
       "      <td>1220602124725153793</td>\n",
       "      <td>#coronavirus</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153521</th>\n",
       "      <td>1220602126587420677</td>\n",
       "      <td>#CoronavirusOutbreak</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153522</th>\n",
       "      <td>1220602128462467072</td>\n",
       "      <td>#coronavirus</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5153523 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Tweet_ID               Hashtag  Year  Month  Day\n",
       "0        1223335138370760705                #China  2020      1   31\n",
       "1        1223335138370760705          #coronavirus  2020      1   31\n",
       "2        1223335138370760705  #CoronavirusOutbreak  2020      1   31\n",
       "3        1223335138756648965        #coronaravirus  2020      1   31\n",
       "4        1223335138895056899          #coronavirus  2020      1   31\n",
       "...                      ...                   ...   ...    ...  ...\n",
       "5153518  1220602122007281671          #coronavirus  2020      1   24\n",
       "5153519  1220602122007281671  #CoronavirusOutbreak  2020      1   24\n",
       "5153520  1220602124725153793          #coronavirus  2020      1   24\n",
       "5153521  1220602126587420677  #CoronavirusOutbreak  2020      1   24\n",
       "5153522  1220602128462467072          #coronavirus  2020      1   24\n",
       "\n",
       "[5153523 rows x 5 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_hash(start,end,types):\n",
    "    files = types\n",
    "\n",
    "    ## define start and end time\n",
    "    startTime = pd.to_datetime(start)\n",
    "    endTime = pd.to_datetime(end)\n",
    "\n",
    "    ## conbine file in certain interval\n",
    "    out = []\n",
    "    for x in files:\n",
    "        temp = '_'.join(x.split('/')[2].split('_',4)[:-1])                    \n",
    "        date = pd.to_datetime(temp,  format='%Y_%m_%d_%H')\n",
    "        #print(date)\n",
    "        if date >= startTime and date <= endTime:\n",
    "            temp = pd.read_csv(x,encoding= 'unicode_escape')\n",
    "            temp['Year'] = date.year\n",
    "            temp['Month'] = date.month\n",
    "            temp['Day'] = date.day\n",
    "            out.append(temp)\n",
    "\n",
    "    combined_csv = pd.concat(out, ignore_index=True)\n",
    "    return combined_csv\n",
    "\n",
    "##-------------test combine_hash-------##\n",
    "combine_hash('2020-01-22 00:00:00','2020-01-31 23:00:00', all_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####-----------------------FOR Summary Detail & Geo code data--------------#######\n",
    "\n",
    "## define the file scope\n",
    "files = all_summ\n",
    "\n",
    "## define start date\n",
    "startTime = '2021-04-01 00:00:00'\n",
    "endTime = '2021-04-30 23:00:00'\n",
    "\n",
    "## define start and end time\n",
    "startTime = pd.to_datetime(startTime)\n",
    "endTime = pd.to_datetime(endTime)\n",
    "\n",
    "## define file_name\n",
    "summ = 'Sum_combine_'+startTime.strftime(\"%Y%m%d\")+'-'+endTime.strftime(\"%Y%m%d\")\n",
    "with_geo = 'Geo_combine_'+startTime.strftime(\"%Y%m%d\")+'-'+endTime.strftime(\"%Y%m%d\")\n",
    "\n",
    "## conbine file in certain interval\n",
    "summ = []\n",
    "with_geo = pd.DataFrame()\n",
    "\n",
    "for x in files:\n",
    "    temp = '_'.join(x.split('/')[2].split('_',4)[:-1])                    \n",
    "    date = pd.to_datetime(temp,  format='%Y_%m_%d_%H')\n",
    "    #print(date)\n",
    "    if date >= startTime and date <= endTime:\n",
    "        temp = pd.read_csv(x,encoding= 'unicode_escape')\n",
    "        temp_count = temp.shape[0]\n",
    "        temp_engcount = temp[temp['Language']=='en'].shape[0]\n",
    "        temp_geocount = temp[temp['Country'].notnull()].shape[0]\n",
    "\n",
    "        summ.append([date.year,date.month,date.day,date.hour,temp_count,temp_engcount,temp_geocount])\n",
    "        \n",
    "        temp_geo = temp[temp['Country'].notnull()][['Tweet_ID','Language','Geolocation_coordinate','Country','Date Created']]\n",
    "        with_geo = with_geo.append(temp_geo,ignore_index=True)\n",
    "\n",
    "summ = pd.DataFrame(summ,columns=['Year','Month','Day','Hour','Count','Eng_count','Geo_count']) \n",
    "\n",
    "#export combined file to csv\n",
    "summ.to_csv('combined_summ_from_{}_to_{}.csv'.format(startTime.date(),endTime.date()), \n",
    "                    index=False, encoding=\"utf-8\",errors='ignore')\n",
    "\n",
    "with_geo.to_csv('combined_geo_from_{}_to_{}.csv'.format(startTime.date(),endTime.date()), \n",
    "                    index=False, encoding=\"utf-8\",errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####-----------------------FOR SENTIMENT SUMM--------------#######\n",
    "\n",
    "## define the file scope\n",
    "files = all_sent\n",
    "\n",
    "## define start date\n",
    "startTime = '2021-04-01 00:00:00'\n",
    "endTime = '2021-04-30 23:00:00'\n",
    "\n",
    "## define start and end time\n",
    "startTime = pd.to_datetime(startTime)\n",
    "endTime = pd.to_datetime(endTime)\n",
    "\n",
    "## define file_name\n",
    "sent = 'Sent_combine_'+startTime.strftime(\"%Y%m%d\")+'-'+endTime.strftime(\"%Y%m%d\")\n",
    "\n",
    "## conbine file in certain interval\n",
    "sent = []\n",
    "\n",
    "\n",
    "for x in files:\n",
    "    temp = '_'.join(x.split('/')[2].split('_',4)[:-1])                    \n",
    "    date = pd.to_datetime(temp,  format='%Y_%m_%d_%H')\n",
    "    #print(date)\n",
    "    if date >= startTime and date <= endTime:\n",
    "        temp = pd.read_csv(x,encoding= 'unicode_escape')\n",
    "        neg_count = temp[temp['Sentiment_Label']=='negative'].shape[0]\n",
    "        pos_count = temp[temp['Sentiment_Label']=='positive'].shape[0]\n",
    "        neu_count = temp[temp['Sentiment_Label']=='neutral'].shape[0]\n",
    "        sent.append([date.year,date.month,date.day,date.hour,neg_count,pos_count,neu_count])\n",
    "        \n",
    "\n",
    "sent = pd.DataFrame(sent,columns=['Year','Month','Day','Hour','Neg_Count','Pos_count','Neu_count']) \n",
    "\n",
    "# export combined file to csv\n",
    "sent.to_csv('combined_sent_from_{}_to_{}.csv'.format(startTime.date(),endTime.date()), \n",
    "                    index=False, encoding=\"utf-8\",errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46899740 entries, 0 to 46899739\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   Tweet_ID  int64 \n",
      " 1   Hashtag   object\n",
      " 2   Year      int64 \n",
      " 3   Month     int64 \n",
      " 4   Day       int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 4.4 GB\n"
     ]
    }
   ],
   "source": [
    "#-------------------check memory usage----------------#\n",
    "combined_csv.info(memory_usage=\"deep\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat209",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
